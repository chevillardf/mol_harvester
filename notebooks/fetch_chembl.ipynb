{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7db3d1a3-9a0e-4e58-95f1-aa17c43ec110",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/florent/Programs/anaconda3/envs/py311/lib/python3.11/site-packages/chembl_webresource_client/__init__.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  __version__ = __import__('pkg_resources').get_distribution('chembl_webresource_client').version\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import PandasTools\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "from chembl_webresource_client.new_client import new_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a713655-bbe1-4336-994a-8e1ec183efc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "assay = new_client.assay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a45949-b912-4476-b6d1-3e4c70117c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching records 0 to 20...\n",
      "Fetching records 20 to 40...\n",
      "Fetching records 40 to 60...\n",
      "Fetching records 60 to 80...\n",
      "Fetching records 80 to 100...\n",
      "Fetching records 100 to 120...\n",
      "Fetching records 120 to 140...\n",
      "Fetching records 140 to 160...\n",
      "Fetching records 160 to 180...\n",
      "Fetching records 180 to 200...\n",
      "Fetching records 200 to 220...\n",
      "Fetching records 220 to 240...\n",
      "Fetching records 240 to 260...\n",
      "Fetching records 260 to 280...\n",
      "Fetching records 280 to 300...\n",
      "Fetching records 300 to 320...\n",
      "Fetching records 320 to 340...\n",
      "Fetching records 340 to 360...\n",
      "Fetching records 360 to 380...\n",
      "Fetching records 380 to 400...\n",
      "Fetching records 400 to 420...\n",
      "Fetching records 420 to 440...\n",
      "Fetching records 440 to 460...\n",
      "Fetching records 460 to 480...\n",
      "Fetching records 480 to 500...\n",
      "Fetching records 500 to 520...\n",
      "Fetching records 520 to 540...\n",
      "Fetching records 540 to 560...\n",
      "Fetching records 560 to 580...\n",
      "Fetching records 580 to 600...\n",
      "Fetching records 600 to 620...\n",
      "Fetching records 620 to 640...\n",
      "Fetching records 640 to 660...\n",
      "Fetching records 660 to 680...\n",
      "Fetching records 680 to 700...\n",
      "Fetching records 700 to 720...\n",
      "Fetching records 720 to 740...\n",
      "Fetching records 740 to 760...\n",
      "Fetching records 760 to 780...\n",
      "Fetching records 780 to 800...\n",
      "Fetching records 800 to 820...\n",
      "Fetching records 820 to 840...\n",
      "Fetching records 840 to 860...\n",
      "Fetching records 860 to 880...\n",
      "Fetching records 880 to 900...\n",
      "Fetching records 900 to 920...\n",
      "Fetching records 920 to 940...\n",
      "Fetching records 940 to 960...\n",
      "Fetching records 960 to 980...\n",
      "Fetching records 980 to 1000...\n",
      "Fetching records 1000 to 1020...\n",
      "Fetching records 1020 to 1040...\n",
      "Fetching records 1040 to 1060...\n",
      "Fetching records 1060 to 1080...\n",
      "Fetching records 1080 to 1100...\n",
      "Fetching records 1100 to 1120...\n",
      "Fetching records 1120 to 1140...\n",
      "Fetching records 1140 to 1160...\n",
      "Fetching records 1160 to 1180...\n",
      "Fetching records 1180 to 1200...\n",
      "Fetching records 1200 to 1220...\n",
      "Fetching records 1220 to 1240...\n",
      "Fetching records 1240 to 1260...\n",
      "Fetching records 1260 to 1280...\n",
      "Fetching records 1280 to 1300...\n",
      "Fetching records 1300 to 1320...\n",
      "Fetching records 1320 to 1340...\n",
      "Fetching records 1340 to 1360...\n",
      "Fetching records 1360 to 1380...\n",
      "Fetching records 1380 to 1400...\n",
      "Fetching records 1400 to 1420...\n",
      "Fetching records 1420 to 1440...\n",
      "Fetching records 1440 to 1460...\n",
      "Fetching records 1460 to 1480...\n",
      "Fetching records 1480 to 1500...\n",
      "Fetching records 1500 to 1520...\n",
      "Fetching records 1520 to 1540...\n",
      "Fetching records 1540 to 1560...\n",
      "Fetching records 1560 to 1580...\n",
      "Fetching records 1580 to 1600...\n",
      "Fetching records 1600 to 1620...\n",
      "Fetching records 1620 to 1640...\n",
      "Fetching records 1640 to 1660...\n",
      "Fetching records 1660 to 1680...\n",
      "Fetching records 1680 to 1700...\n",
      "Fetching records 1700 to 1720...\n",
      "Fetching records 1720 to 1740...\n",
      "Fetching records 1740 to 1760...\n",
      "Fetching records 1760 to 1780...\n",
      "Fetching records 1780 to 1800...\n",
      "Fetching records 1800 to 1820...\n",
      "Fetching records 1820 to 1840...\n",
      "Fetching records 1840 to 1860...\n",
      "Fetching records 1860 to 1880...\n",
      "Fetching records 1880 to 1900...\n",
      "Fetching records 1900 to 1920...\n",
      "Fetching records 1920 to 1940...\n",
      "Fetching records 1940 to 1960...\n",
      "Fetching records 1960 to 1980...\n",
      "Fetching records 1980 to 2000...\n",
      "Created ../data/raw/test_1M.csv and wrote first chunk (2000 records)\n",
      "Total records written so far: 2000\n",
      "Fetching records 2000 to 2020...\n",
      "Fetching records 2020 to 2040...\n",
      "Fetching records 2040 to 2060...\n",
      "Fetching records 2060 to 2080...\n",
      "Fetching records 2080 to 2100...\n",
      "Fetching records 2100 to 2120...\n",
      "Fetching records 2120 to 2140...\n",
      "Fetching records 2140 to 2160...\n",
      "Fetching records 2160 to 2180...\n",
      "Fetching records 2180 to 2200...\n",
      "Fetching records 2200 to 2220...\n",
      "Fetching records 2220 to 2240...\n",
      "Fetching records 2240 to 2260...\n",
      "Fetching records 2260 to 2280...\n",
      "Fetching records 2280 to 2300...\n",
      "Fetching records 2300 to 2320...\n",
      "Fetching records 2320 to 2340...\n",
      "Fetching records 2340 to 2360...\n",
      "Fetching records 2360 to 2380...\n",
      "Fetching records 2380 to 2400...\n",
      "Fetching records 2400 to 2420...\n",
      "Fetching records 2420 to 2440...\n",
      "Fetching records 2440 to 2460...\n",
      "Fetching records 2460 to 2480...\n",
      "Fetching records 2480 to 2500...\n",
      "Fetching records 2500 to 2520...\n",
      "Fetching records 2520 to 2540...\n",
      "Fetching records 2540 to 2560...\n",
      "Fetching records 2560 to 2580...\n",
      "Fetching records 2580 to 2600...\n",
      "Fetching records 2600 to 2620...\n",
      "Fetching records 2620 to 2640...\n"
     ]
    }
   ],
   "source": [
    "batch_size = 20\n",
    "offset = 0\n",
    "max_records = 1000000  # or None for full\n",
    "rawfile = \"../data/raw/test_1M.csv\"\n",
    "\n",
    "# Batch collection settings\n",
    "write_frequency = 100  # Write every 100 batches\n",
    "results = []  # Temporary storage for batches\n",
    "first_write = True\n",
    "total_records = 0\n",
    "batch_count = 0\n",
    "\n",
    "while True:\n",
    "    print(f\"Fetching records {offset} to {offset + batch_size}...\")\n",
    "    \n",
    "    batch = assay.filter(\n",
    "        assay_type='A',\n",
    "        assay_organism__iexact='Homo sapiens'\n",
    "    ).only(['assay_type', 'description', 'assay_chembl_id', 'assay_organism'])[offset:offset + batch_size]\n",
    "    \n",
    "    if not batch:\n",
    "        break\n",
    "    \n",
    "    # Convert batch to DataFrame and collect\n",
    "    df_batch = pd.DataFrame(batch)\n",
    "    results.append(df_batch)\n",
    "    batch_count += 1\n",
    "    \n",
    "    # Write every 100 batches or when we reach max_records\n",
    "    should_write = (batch_count % write_frequency == 0) or (max_records and offset + batch_size >= max_records)\n",
    "    \n",
    "    if should_write:\n",
    "        # Combine collected batches\n",
    "        chunk_df = pd.concat(results, ignore_index=True)\n",
    "        \n",
    "        # Write to CSV\n",
    "        if first_write:\n",
    "            chunk_df.to_csv(rawfile, mode='w', header=True, index=False)\n",
    "            print(f\"Created {rawfile} and wrote first chunk ({len(chunk_df)} records)\")\n",
    "            first_write = False\n",
    "        else:\n",
    "            chunk_df.to_csv(rawfile, mode='a', header=False, index=False)\n",
    "            print(f\"Appended chunk ({len(chunk_df)} records)\")\n",
    "        \n",
    "        total_records += len(chunk_df)\n",
    "        print(f\"Total records written so far: {total_records}\")\n",
    "        \n",
    "        # Clear memory\n",
    "        results.clear()\n",
    "    \n",
    "    offset += batch_size\n",
    "    if max_records and offset >= max_records:\n",
    "        break\n",
    "    time.sleep(0.5)  # adjust delay if needed\n",
    "\n",
    "# Write any remaining batches\n",
    "if results:\n",
    "    final_chunk = pd.concat(results, ignore_index=True)\n",
    "    if first_write:\n",
    "        final_chunk.to_csv(rawfile, mode='w', header=True, index=False)\n",
    "    else:\n",
    "        final_chunk.to_csv(rawfile, mode='a', header=False, index=False)\n",
    "    total_records += len(final_chunk)\n",
    "    print(f\"Wrote final chunk ({len(final_chunk)} records)\")\n",
    "\n",
    "if total_records > 0:\n",
    "    print(f\"\\n✅ Successfully wrote {total_records} records to {rawfile}\")\n",
    "else:\n",
    "    print(\"\\n⚠️ No data retrieved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9534e3-0390-4829-aefb-831954facb78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
