{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import PandasTools\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "from chembl_webresource_client.new_client import new_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "assay = new_client.assay\n",
    "activity = new_client.activity\n",
    "molecule = new_client.molecule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract assay type A in Human"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching records 0 to 20...\n",
      "Fetching records 20 to 40...\n",
      "Fetching records 40 to 60...\n",
      "Fetching records 60 to 80...\n",
      "Fetching records 80 to 100...\n",
      "Fetching records 100 to 120...\n",
      "Fetching records 120 to 140...\n",
      "Fetching records 140 to 160...\n",
      "Fetching records 160 to 180...\n",
      "Fetching records 180 to 200...\n",
      "Fetching records 200 to 220...\n",
      "Fetching records 220 to 240...\n",
      "Fetching records 240 to 260...\n",
      "Fetching records 260 to 280...\n",
      "Fetching records 280 to 300...\n",
      "Fetching records 300 to 320...\n",
      "Fetching records 320 to 340...\n",
      "Fetching records 340 to 360...\n",
      "Fetching records 360 to 380...\n",
      "Fetching records 380 to 400...\n",
      "Fetching records 400 to 420...\n",
      "Fetching records 420 to 440...\n",
      "Fetching records 440 to 460...\n",
      "Fetching records 460 to 480...\n",
      "Fetching records 480 to 500...\n",
      "Fetching records 500 to 520...\n",
      "Fetching records 520 to 540...\n",
      "Fetching records 540 to 560...\n",
      "Fetching records 560 to 580...\n",
      "Fetching records 580 to 600...\n",
      "Fetching records 600 to 620...\n",
      "Fetching records 620 to 640...\n",
      "Fetching records 640 to 660...\n",
      "Fetching records 660 to 680...\n",
      "Fetching records 680 to 700...\n",
      "Fetching records 700 to 720...\n",
      "Fetching records 720 to 740...\n",
      "Fetching records 740 to 760...\n",
      "Fetching records 760 to 780...\n",
      "Fetching records 780 to 800...\n",
      "Fetching records 800 to 820...\n",
      "Fetching records 820 to 840...\n",
      "Fetching records 840 to 860...\n",
      "Fetching records 860 to 880...\n",
      "Fetching records 880 to 900...\n",
      "Fetching records 900 to 920...\n",
      "Fetching records 920 to 940...\n",
      "Fetching records 940 to 960...\n",
      "Fetching records 960 to 980...\n",
      "Fetching records 980 to 1000...\n",
      "Fetching records 1000 to 1020...\n",
      "Fetching records 1020 to 1040...\n",
      "Fetching records 1040 to 1060...\n",
      "Fetching records 1060 to 1080...\n",
      "Fetching records 1080 to 1100...\n",
      "Fetching records 1100 to 1120...\n",
      "Fetching records 1120 to 1140...\n",
      "Fetching records 1140 to 1160...\n",
      "Fetching records 1160 to 1180...\n",
      "Fetching records 1180 to 1200...\n",
      "Fetching records 1200 to 1220...\n",
      "Fetching records 1220 to 1240...\n",
      "Fetching records 1240 to 1260...\n",
      "Fetching records 1260 to 1280...\n",
      "Fetching records 1280 to 1300...\n",
      "Fetching records 1300 to 1320...\n",
      "Fetching records 1320 to 1340...\n",
      "Fetching records 1340 to 1360...\n",
      "Fetching records 1360 to 1380...\n",
      "Fetching records 1380 to 1400...\n",
      "Fetching records 1400 to 1420...\n",
      "Fetching records 1420 to 1440...\n",
      "Fetching records 1440 to 1460...\n",
      "Fetching records 1460 to 1480...\n",
      "Fetching records 1480 to 1500...\n",
      "Fetching records 1500 to 1520...\n",
      "Fetching records 1520 to 1540...\n",
      "Fetching records 1540 to 1560...\n",
      "Fetching records 1560 to 1580...\n",
      "Fetching records 1580 to 1600...\n",
      "Fetching records 1600 to 1620...\n",
      "Fetching records 1620 to 1640...\n",
      "Fetching records 1640 to 1660...\n",
      "Fetching records 1660 to 1680...\n",
      "Fetching records 1680 to 1700...\n",
      "Fetching records 1700 to 1720...\n",
      "Fetching records 1720 to 1740...\n",
      "Fetching records 1740 to 1760...\n",
      "Fetching records 1760 to 1780...\n",
      "Fetching records 1780 to 1800...\n",
      "Fetching records 1800 to 1820...\n",
      "Fetching records 1820 to 1840...\n",
      "Fetching records 1840 to 1860...\n",
      "Fetching records 1860 to 1880...\n",
      "Fetching records 1880 to 1900...\n",
      "Fetching records 1900 to 1920...\n",
      "Fetching records 1920 to 1940...\n",
      "Fetching records 1940 to 1960...\n",
      "Fetching records 1960 to 1980...\n",
      "Fetching records 1980 to 2000...\n",
      "Fetching records 2000 to 2020...\n",
      "Fetching records 2020 to 2040...\n",
      "Fetching records 2040 to 2060...\n",
      "Fetching records 2060 to 2080...\n",
      "Fetching records 2080 to 2100...\n",
      "Fetching records 2100 to 2120...\n",
      "Fetching records 2120 to 2140...\n",
      "Fetching records 2140 to 2160...\n",
      "Fetching records 2160 to 2180...\n",
      "Fetching records 2180 to 2200...\n",
      "Fetching records 2200 to 2220...\n",
      "Fetching records 2220 to 2240...\n",
      "Fetching records 2240 to 2260...\n",
      "Fetching records 2260 to 2280...\n",
      "Fetching records 2280 to 2300...\n",
      "Fetching records 2300 to 2320...\n",
      "Fetching records 2320 to 2340...\n",
      "Fetching records 2340 to 2360...\n",
      "Fetching records 2360 to 2380...\n",
      "Fetching records 2380 to 2400...\n",
      "Fetching records 2400 to 2420...\n",
      "Fetching records 2420 to 2440...\n",
      "Fetching records 2440 to 2460...\n",
      "Fetching records 2460 to 2480...\n",
      "Fetching records 2480 to 2500...\n",
      "Fetching records 2500 to 2520...\n",
      "Fetching records 2520 to 2540...\n",
      "Fetching records 2540 to 2560...\n",
      "Fetching records 2560 to 2580...\n",
      "Fetching records 2580 to 2600...\n",
      "Fetching records 2600 to 2620...\n",
      "Fetching records 2620 to 2640...\n",
      "Fetching records 2640 to 2660...\n",
      "Fetching records 2660 to 2680...\n",
      "Fetching records 2680 to 2700...\n",
      "Fetching records 2700 to 2720...\n",
      "Fetching records 2720 to 2740...\n",
      "Fetching records 2740 to 2760...\n",
      "Fetching records 2760 to 2780...\n",
      "Fetching records 2780 to 2800...\n",
      "Fetching records 2800 to 2820...\n",
      "Fetching records 2820 to 2840...\n",
      "Fetching records 2840 to 2860...\n",
      "Fetching records 2860 to 2880...\n",
      "Fetching records 2880 to 2900...\n",
      "Fetching records 2900 to 2920...\n",
      "Fetching records 2920 to 2940...\n",
      "Fetching records 2940 to 2960...\n",
      "Fetching records 2960 to 2980...\n",
      "Fetching records 2980 to 3000...\n",
      "Fetching records 3000 to 3020...\n",
      "Fetching records 3020 to 3040...\n",
      "Fetching records 3040 to 3060...\n",
      "Fetching records 3060 to 3080...\n",
      "Fetching records 3080 to 3100...\n",
      "Fetching records 3100 to 3120...\n",
      "Fetching records 3120 to 3140...\n",
      "Fetching records 3140 to 3160...\n",
      "Fetching records 3160 to 3180...\n",
      "Fetching records 3180 to 3200...\n",
      "Fetching records 3200 to 3220...\n",
      "Fetching records 3220 to 3240...\n",
      "Fetching records 3240 to 3260...\n",
      "Fetching records 3260 to 3280...\n",
      "Fetching records 3280 to 3300...\n",
      "Fetching records 3300 to 3320...\n",
      "Fetching records 3320 to 3340...\n",
      "Fetching records 3340 to 3360...\n",
      "Fetching records 3360 to 3380...\n",
      "Fetching records 3380 to 3400...\n",
      "Fetching records 3400 to 3420...\n",
      "Fetching records 3420 to 3440...\n",
      "Fetching records 3440 to 3460...\n",
      "Fetching records 3460 to 3480...\n",
      "Fetching records 3480 to 3500...\n",
      "Fetching records 3500 to 3520...\n",
      "Fetching records 3520 to 3540...\n",
      "Fetching records 3540 to 3560...\n",
      "Fetching records 3560 to 3580...\n",
      "Fetching records 3580 to 3600...\n",
      "Fetching records 3600 to 3620...\n",
      "Fetching records 3620 to 3640...\n",
      "Fetching records 3640 to 3660...\n",
      "Fetching records 3660 to 3680...\n",
      "Fetching records 3680 to 3700...\n",
      "Fetching records 3700 to 3720...\n",
      "Fetching records 3720 to 3740...\n",
      "Fetching records 3740 to 3760...\n",
      "Fetching records 3760 to 3780...\n",
      "Fetching records 3780 to 3800...\n",
      "Fetching records 3800 to 3820...\n",
      "Fetching records 3820 to 3840...\n",
      "Fetching records 3840 to 3860...\n",
      "Fetching records 3860 to 3880...\n",
      "Fetching records 3880 to 3900...\n",
      "Fetching records 3900 to 3920...\n"
     ]
    }
   ],
   "source": [
    "batch_size = 20\n",
    "offset = 0\n",
    "max_records = 1000000  # or None for full\n",
    "results = []\n",
    "rawfile = \"../data/raw/test_1M.csv\"\n",
    "\n",
    "while True:\n",
    "    print(f\"Fetching records {offset} to {offset + batch_size}...\")\n",
    "    \n",
    "    batch = assay.filter(\n",
    "        assay_type='A',\n",
    "        assay_organism__iexact='Homo sapiens'\n",
    "    ).only(['assay_type', 'description', 'assay_chembl_id', 'assay_organism'])[offset:offset + batch_size]\n",
    "\n",
    "    if not batch:\n",
    "        break\n",
    "\n",
    "    df_batch = pd.DataFrame(batch)\n",
    "    results.append(df_batch)\n",
    "\n",
    "    offset += batch_size\n",
    "    if max_records and offset >= max_records:\n",
    "        break\n",
    "\n",
    "    time.sleep(0.5)  # adjust delay if needed\n",
    "\n",
    "if results:\n",
    "    final_df = pd.concat(results, ignore_index=True)\n",
    "    final_df.to_csv(rawfile, index=False)\n",
    "    print(f\"\\n✅ Wrote {len(final_df)} records to {rawfile}\")\n",
    "else:\n",
    "    print(\"\\n⚠️ No data retrieved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieve HLM activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 263 ms, sys: 19.6 ms, total: 283 ms\n",
      "Wall time: 282 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7037, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_csv(rawfile)\n",
    "#pattern = r'(?i)\\b(?:CL|microsome|HLM_CL|HLM_clearance|HLM_half_life|HLM_stability)\\b' # more specific\n",
    "pattern = r'(?i)\\b(?:CL|microsome|HLM|stability)\\b' # broader\n",
    "hlm_df = df[df['description'].str.contains(pattern, na=False)]\n",
    "hlm_assay_ids = hlm_df['assay_chembl_id'].tolist()\n",
    "hlm_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1000  # Adjust as needed\n",
    "all_activities = []\n",
    "\n",
    "for i in range(0, len(hlm_assay_ids), batch_size):\n",
    "    batch = hlm_assay_ids[i:i + batch_size]\n",
    "    print(f\"Fetching batch {i // batch_size + 1} of {len(hlm_assay_ids) // batch_size + 1}\")\n",
    "    res = activity.filter(assay_chembl_id__in=batch).only([\n",
    "        'molecule_chembl_id', 'assay_chembl_id',\n",
    "        'standard_value', 'standard_units', 'standard_type',\n",
    "        'standard_relation', 'document_chembl_id', 'description'\n",
    "    ])\n",
    "    all_activities.extend(res)\n",
    "    time.sleep(0.5)  # Avoid hammering the API\n",
    "\n",
    "activities_df = pd.DataFrame(all_activities)\n",
    "activities_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities_df.to_csv('../data/mols_hlm.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieve molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities_df = pd.read_csv(\"../data/mols_hlm.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26608"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_molecule_ids = activities_df['molecule_chembl_id'].unique().tolist()\n",
    "len(unique_molecule_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = molecule.filter(chembl_id__in=['CHEMBL152844']).only([\n",
    "    'molecule_chembl_id',\n",
    "    'molecule_structures'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2496335"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mols_df = pd.DataFrame(res)\n",
    "mols_df['mol_smi'] = mols_df['molecule_structures'].apply(lambda x: x.get('canonical_smiles') if isinstance(x, dict) else None)\n",
    "mols_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1000\n",
    "all_molecules = []\n",
    "\n",
    "for i in range(0, len(unique_molecule_ids), batch_size):\n",
    "    batch = unique_molecule_ids[i:i + batch_size]\n",
    "    print(f\"Fetching batch {i // batch_size + 1} of {(len(unique_molecule_ids) + batch_size - 1) // batch_size}\")\n",
    "    \n",
    "    res = molecule.filter(chembl_id__in=batch).only([\n",
    "        'molecule_chembl_id',\n",
    "        'molecule_structures'\n",
    "    ])\n",
    "    \n",
    "    all_molecules.extend(res)\n",
    "    time.sleep(0.5)  # Rate limit friendly\n",
    "\n",
    "mols_df = pd.DataFrame(all_molecules)\n",
    "print(f\"Retrieved {len(mols_df)} molecules.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis + Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities_df['standard_type'].value_counts().head(29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp['document_chembl_id'].value_counts().head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "ax = sns.countplot(full_data, x='standard_type')\n",
    "plt.xticks(rotation=45, ha='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# 10k = 98s\n",
    "assays = assay.filter(\n",
    "    assay_type='A',\n",
    "    assay_organism__iexact='Homo sapiens'\n",
    ").only(['assay_type', 'description', 'assay_chembl_id', 'assay_organism'])[:10000]\n",
    "df = pd.DataFrame(assays)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt = activities_df['standard_type'] == 'CL'\n",
    "tmp = activities_df[filt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt = activities_df['document_chembl_id'] == 'CHEMBL4342426'\n",
    "tmp = activities_df[filt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Look at molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data['mol_smi'] = full_data['molecule_structures'].apply(lambda x: x.get('canonical_smiles') if isinstance(x, dict) else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PandasTools.AddMoleculeColumnToFrame(\n",
    "    tmp, \n",
    "    smilesCol='mol_smi',  # Column containing SMILES strings\n",
    "    molCol='Molecule',             # Name of new column to create\n",
    "    includeFingerprints=False      # Set to True if you need fingerprints\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Extract hERG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chembl_webresource_client.new_client import new_client\n",
    "\n",
    "target = new_client.target\n",
    "activity = new_client.activity\n",
    "herg = target.filter(pref_name__iexact='hERG').only('target_chembl_id')[0]\n",
    "herg_activities = activity.filter(target_chembl_id=herg['target_chembl_id']).filter(standard_type=\"IC50\")\n",
    "\n",
    "herg_activities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Extract HLM data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_metabolic_assays(limit=1000):\n",
    "    url = f\"https://www.ebi.ac.uk/chembl/api/data/assay.json?assay_type=ADME&limit={limit}\"\n",
    "    assays = []\n",
    "    while url:\n",
    "        res = requests.get(url)\n",
    "        res.raise_for_status()\n",
    "        data = res.json()\n",
    "        for a in data[\"assays\"]:\n",
    "            if \"metabolic\" in (a.get(\"description\") or \"\").lower():\n",
    "                assays.append(a[\"assay_chembl_id\"])\n",
    "        url = data[\"page_meta\"][\"next\"]\n",
    "    return assays\n",
    "\n",
    "def fetch_activities_for_assays(assay_ids, limit=1000):\n",
    "    activities = []\n",
    "    for assay_id in assay_ids:\n",
    "        url = f\"https://www.ebi.ac.uk/chembl/api/data/activity.json?assay_chembl_id={assay_id}&limit={limit}\"\n",
    "        while url:\n",
    "            res = requests.get(url)\n",
    "            res.raise_for_status()\n",
    "            data = res.json()\n",
    "            activities.extend(data[\"activities\"])\n",
    "            url = data[\"page_meta\"][\"next\"]\n",
    "    return activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assay_ids = fetch_metabolic_assays()\n",
    "print(f\"Found {len(assay_ids)} assays likely related to metabolic stability.\")\n",
    "\n",
    "activities = fetch_activities_for_assays(assay_ids[:5])  # You can increase the slice\n",
    "print(f\"Retrieved {len(activities)} activity records.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Get molecules w/ logP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_molecules_with_logp_and_docs(limit=100, max_pages=None, verbose=True):\n",
    "    url = f\"{base_url}/chembl/api/data/molecule.json?logp__isnull=false&molecule_documents__isnull=false&limit={limit}\"\n",
    "    molecules = []\n",
    "    page = 0\n",
    "    \n",
    "    while url and (max_pages is None or page < max_pages):\n",
    "        if verbose:\n",
    "            print(f\"Fetching page {page + 1}...\")\n",
    "        res = requests.get(url)\n",
    "        res.raise_for_status()\n",
    "        data = res.json()\n",
    "        molecules.extend(data['molecules'])\n",
    "\n",
    "        next_url = data['page_meta']['next']\n",
    "        url = f\"{base_url}{next_url}\" if next_url else None\n",
    "        page += 1\n",
    "\n",
    "    return molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "molecules = fetch_molecules_with_logp_and_docs(limit=50, max_pages=1)\n",
    "\n",
    "with open(\"../data/raw/chembl_logP_molecules.json\", \"w\") as f:\n",
    "    json.dump(molecules, f, indent=2)\n",
    "\n",
    "print(f\"Fetched {len(molecules)} molecules with logP.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(molecules)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['molecule_structures', 'molecule_chembl_id', 'molecule_properties']]\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test API with a known molecule Chembl ID\n",
    "chembl_id = \"CHEMBL6329\"\n",
    "url = f\"https://www.ebi.ac.uk/chembl/api/data/document.json?molecule_chembl_id={chembl_id}\"\n",
    "res = requests.get(url)\n",
    "res.raise_for_status()\n",
    "data = res.json()\n",
    "documents = data.get(\"documents\", [])\n",
    "df = pd.DataFrame(documents)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get all activities in CHemBL \n",
    "url = \"https://www.ebi.ac.uk/chembl/api/data/activity.json?limit=1000\"\n",
    "res = requests.get(url)\n",
    "res.raise_for_status()\n",
    "data = res.json()\n",
    "\n",
    "types = {a[\"standard_type\"] for a in data[\"activities\"] if a.get(\"standard_type\")}\n",
    "types = sorted(types)\n",
    "for t in types:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Get document_id for subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fetch documents associated with a molecule\n",
    "def get_documents_for_molecule(chembl_id):\n",
    "    url = f\"https://www.ebi.ac.uk/chembl/api/data/document.json?molecule_chembl_id={chembl_id}\"\n",
    "    res = requests.get(url)\n",
    "    res.raise_for_status()\n",
    "    return res.json().get(\"documents\", [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chembl_id = \"CHEMBL25\"\n",
    "documents = get_documents_for_molecule(chembl_id)\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add document IDs to each molecule\n",
    "def fetch_documents_for_molecules(molecules):\n",
    "    doc_map = {}\n",
    "    for mol in molecules:\n",
    "        chembl_id = mol.get(\"molecule_chembl_id\")\n",
    "        if chembl_id:\n",
    "            docs = get_documents_for_molecule(chembl_id)\n",
    "            doc_ids = [d[\"document_chembl_id\"] for d in docs]\n",
    "            doc_map[chembl_id] = doc_ids\n",
    "    return doc_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_map = fetch_documents_for_molecules(molecules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(molecules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"logP\"] = df[\"molecule_properties\"].apply(\n",
    "    lambda x: x.get(\"alogp\") if isinstance(x, dict) else None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"document_ids\"] = df[\"molecule_chembl_id\"].map(doc_map)\n",
    "\n",
    "# Show merged DataFrame\n",
    "df_merged = df[[\"molecule_chembl_id\", \"logP\", \"document_ids\"]]\n",
    "print(df_merged.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get molecules from document_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_molecules_for_document(document_id):\n",
    "    url = f\"https://www.ebi.ac.uk/chembl/api/data/molecule_document.json?document_chembl_id={document_id}\"\n",
    "    res = requests.get(url)\n",
    "    res.raise_for_status()\n",
    "    return res.json().get(\"molecule_documents\", [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Get molecules associated with a document\n",
    "document_id = \"CHEMBL1158643\"\n",
    "molecule_docs = get_molecules_for_document(document_id)\n",
    "\n",
    "# Print out the molecule ChEMBL IDs\n",
    "molecule_ids = [doc[\"molecule_chembl_id\"] for doc in molecule_docs]\n",
    "print(f\"Molecule ChEMBL IDs for document {document_id}: {molecule_ids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_molecules_with_logp_and_patents(limit=100, max_pages=None, verbose=True):\n",
    "    base_url = \"https://www.ebi.ac.uk\"\n",
    "    url = f\"{base_url}/chembl/api/data/molecule.json?logp__isnull=false&molecule_patents__isnull=false&limit={limit}\"\n",
    "    molecules = []\n",
    "    page = 0\n",
    "\n",
    "    while url and (max_pages is None or page < max_pages):\n",
    "        if verbose:\n",
    "            print(f\"Fetching page {page + 1}...\")\n",
    "        res = requests.get(url)\n",
    "        res.raise_for_status()\n",
    "        data = res.json()\n",
    "        molecules.extend(data['molecules'])\n",
    "\n",
    "        next_url = data['page_meta'].get('next')\n",
    "        url = f\"{base_url}{next_url}\" if next_url else None\n",
    "        page += 1\n",
    "\n",
    "    return molecules\n",
    "\n",
    "def fetch_molecules_with_logp_smiles_and_patents(limit=100, max_pages=None, verbose=True):\n",
    "    base_url = \"https://www.ebi.ac.uk\"\n",
    "    url = f\"{base_url}/chembl/api/data/molecule.json?logp__isnull=false&molecule_patents__isnull=false&limit={limit}\"\n",
    "    molecules = []\n",
    "    page = 0\n",
    "\n",
    "    while url and (max_pages is None or page < max_pages):\n",
    "        if verbose:\n",
    "            print(f\"Fetching page {page + 1}...\")\n",
    "        res = requests.get(url)\n",
    "        res.raise_for_status()\n",
    "        data = res.json()\n",
    "        molecules.extend(data['molecules'])\n",
    "\n",
    "        next_url = data['page_meta'].get('next')\n",
    "        url = f\"{base_url}{next_url}\" if next_url else None\n",
    "        page += 1\n",
    "\n",
    "    # Fetch SMILES and Patent IDs for each molecule\n",
    "    molecules_with_smiles_and_patents = []\n",
    "    for molecule in molecules:\n",
    "        patent_ids = []\n",
    "        smiles = None\n",
    "        \n",
    "        # Get SMILES from molecule_structures\n",
    "        if 'molecule_structures' in molecule:\n",
    "            smiles = molecule['molecule_structures'].get('canonical_smiles', None)\n",
    "        \n",
    "        # Get patent IDs from molecule_patents\n",
    "        if 'molecule_patents' in molecule:\n",
    "            patent_ids = [patent['patent_chembl_id'] for patent in molecule['molecule_patents']]\n",
    "        \n",
    "        # Add SMILES and patent IDs to molecule data\n",
    "        molecule['smiles'] = smiles\n",
    "        molecule['patent_ids'] = patent_ids\n",
    "        molecules_with_smiles_and_patents.append(molecule)\n",
    "\n",
    "    return molecules_with_smiles_and_patents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
