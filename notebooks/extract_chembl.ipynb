{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import PandasTools\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "from chembl_webresource_client.new_client import new_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "assay = new_client.assay\n",
    "activity = new_client.activity\n",
    "molecule = new_client.molecule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract assay type A in Human"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "offset = 0\n",
    "max_records = 1000000  # or None for full\n",
    "results = []\n",
    "rawfile = \"../data/raw/test_1M.csv\"\n",
    "\n",
    "while True:\n",
    "    print(f\"Fetching records {offset} to {offset + batch_size}...\")\n",
    "    \n",
    "    batch = assay.filter(\n",
    "        assay_type='A',\n",
    "        assay_organism__iexact='Homo sapiens'\n",
    "    ).only(['assay_type', 'description', 'assay_chembl_id', 'assay_organism'])[offset:offset + batch_size]\n",
    "\n",
    "    if not batch:\n",
    "        break\n",
    "\n",
    "    df_batch = pd.DataFrame(batch)\n",
    "    results.append(df_batch)\n",
    "\n",
    "    offset += batch_size\n",
    "    if max_records and offset >= max_records:\n",
    "        break\n",
    "\n",
    "    time.sleep(0.5)  # adjust delay if needed\n",
    "\n",
    "if results:\n",
    "    final_df = pd.concat(results, ignore_index=True)\n",
    "    final_df.to_csv(rawfile, index=False)\n",
    "    print(f\"\\n✅ Wrote {len(final_df)} records to {rawfile}\")\n",
    "else:\n",
    "    print(\"\\n⚠️ No data retrieved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieve HLM activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6952, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter HLM related terms only + get assays id\n",
    "df = pd.read_csv('../data/raw/test_100k.csv')\n",
    "pattern = re.compile(r'(?i)\\b(?:HLM|human.*liver.*microsome|microsomal.*clearance|intrinsic.*clearance|metabolic.{0,3}stabil(?:ity|e))\\b') # very specific\n",
    "#pattern = r'(?i)\\b(?:CL|microsome|HLM_CL|HLM_clearance|HLM_half_life|HLM_stability)\\b' # more specific\n",
    "hlm_df = df[df['description'].str.contains(pattern, na=False)]\n",
    "hlm_assay_ids = hlm_df['assay_chembl_id'].tolist()\n",
    "hlm_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20  # API limit to avoid throttling\n",
    "activities_file = \"../data/staging/hlm_activities.csv\"\n",
    "first_batch = True\n",
    "total_activities = 0\n",
    "\n",
    "for i in range(0, len(hlm_assay_ids), batch_size):\n",
    "    batch = hlm_assay_ids[i:i + batch_size]\n",
    "    batch_num = i // batch_size + 1\n",
    "    total_batches = (len(hlm_assay_ids) - 1) // batch_size + 1\n",
    "    print(f\"Fetching batch {batch_num} of {total_batches} ({len(batch)} assay IDs)\")\n",
    "    \n",
    "    try:\n",
    "        res = activity.filter(assay_chembl_id__in=batch).only([\n",
    "            'molecule_chembl_id', 'assay_chembl_id',\n",
    "            'standard_value', 'standard_units', 'standard_type',\n",
    "            'standard_relation', 'document_chembl_id', 'description'\n",
    "        ])\n",
    "        \n",
    "        if res:\n",
    "            batch_df = pd.DataFrame(res)\n",
    "            if first_batch:\n",
    "                batch_df.to_csv(activities_file, mode='w', header=True, index=False)\n",
    "                print(f\"Created {activities_file} with {len(batch_df)} activities\")\n",
    "                first_batch = False\n",
    "            else:\n",
    "                batch_df.to_csv(activities_file, mode='a', header=False, index=False)\n",
    "                print(f\"Appended {len(batch_df)} activities\")\n",
    "            \n",
    "            total_activities += len(batch_df)\n",
    "            print(f\"Total activities so far: {total_activities}\")\n",
    "        else:\n",
    "            print(\"No activities found for this batch\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error in batch {batch_num}: {e}\")\n",
    "        # Continue with next batch or implement retry logic\n",
    "        continue\n",
    "    \n",
    "    time.sleep(1.0)  # Longer delay to avoid throttling\n",
    "\n",
    "print(f\"\\n✅ Total activities retrieved: {total_activities}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only CL for HLM values\n",
    "filt = activities_df['standard_type'] == 'CL'\n",
    "hlm_df = activities_df[filt]\n",
    "hlm_df.to_csv('../data/staging/hlm_activities_CL.csv', index=False)\n",
    "hlm_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DF exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dataset shape: (18424, 11)\n"
     ]
    }
   ],
   "source": [
    "hlm_df = pd.read_csv('../data/staging/hlm_activities_CL.csv')\n",
    "print(f\"Final dataset shape: {hlm_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hlm_df['document_chembl_id'].value_counts().head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hlm_df['assay_chembl_id'].value_counts().head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AZ data set: doc = CHEMBL3301361 = assay(CHEMBL3301370 + CHEMBL3301372)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1510, 11)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filt = hlm_df['document_chembl_id'] == 'CHEMBL3301361'\n",
    "hlm_df = hlm_df[filt]\n",
    "hlm_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieve molecules from subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1510"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_molecule_ids = hlm_df['molecule_chembl_id'].unique().tolist()\n",
    "len(hlm_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from typing import List, Dict, Optional\n",
    "\n",
    "def get_smiles_via_rest_optimized(chembl_id: str) -> Dict[str, Optional[str]]:\n",
    "    \"\"\"Optimized single request function\"\"\"\n",
    "    url = f\"https://www.ebi.ac.uk/chembl/api/data/molecule/{chembl_id}.json\"\n",
    "    try:\n",
    "        response = requests.get(url, timeout=5)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            smiles = data.get('molecule_structures', {}).get('canonical_smiles')\n",
    "            return {'molecule_chembl_id': chembl_id, 'canonical_smiles': smiles}\n",
    "    except Exception as e:\n",
    "        print(f\"REST API error for {chembl_id}: {e}\")\n",
    "    \n",
    "    return {'molecule_chembl_id': chembl_id, 'canonical_smiles': None}\n",
    "\n",
    "def get_smiles_parallel(chembl_ids: List[str], max_workers: int = 5) -> pd.DataFrame:\n",
    "    \"\"\"Use ThreadPoolExecutor for parallel requests within a chunk\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        # Submit all requests\n",
    "        future_to_id = {\n",
    "            executor.submit(get_smiles_via_rest_optimized, mol_id): mol_id \n",
    "            for mol_id in chembl_ids\n",
    "        }\n",
    "        \n",
    "        # Collect results as they complete\n",
    "        for future in as_completed(future_to_id):\n",
    "            result = future.result()\n",
    "            results.append(result)\n",
    "            time.sleep(0.05)  # Small delay between processing results\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "def get_smiles_chunked_parallel(unique_molecule_ids: List[str], \n",
    "                               chunk_size: int = 100, \n",
    "                               max_workers: int = 5) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Process in chunks with parallel requests within each chunk\n",
    "    Best balance of speed and API courtesy\n",
    "    \"\"\"\n",
    "    all_results = []\n",
    "    \n",
    "    for i in range(0, len(unique_molecule_ids), chunk_size):\n",
    "        chunk = unique_molecule_ids[i:i + chunk_size]\n",
    "        chunk_num = i//chunk_size + 1\n",
    "        total_chunks = (len(unique_molecule_ids)-1)//chunk_size + 1\n",
    "        \n",
    "        print(f\"Processing chunk {chunk_num}/{total_chunks} ({len(chunk)} molecules)\")\n",
    "        \n",
    "        chunk_df = get_smiles_parallel(chunk, max_workers=max_workers)\n",
    "        all_results.append(chunk_df)\n",
    "        \n",
    "        # Longer pause between chunks to be respectful to the API\n",
    "        if i + chunk_size < len(unique_molecule_ids):\n",
    "            print(f\"Completed chunk {chunk_num}, pausing before next chunk...\")\n",
    "            time.sleep(2)\n",
    "    \n",
    "    return pd.concat(all_results, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(\"Starting chunked parallel SMILES retrieval...\")\n",
    "smiles_df = get_smiles_chunked_parallel(unique_molecule_ids, chunk_size=20, max_workers=5)\n",
    "print(f\"Retrieved {len(smiles_df)} records total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles_df.to_csv('../data/staging/hlm_activities_CL_smi.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = hlm_df.merge(\n",
    "    smiles_df, \n",
    "    on='molecule_chembl_id', \n",
    "    how='left'  # Keep all activities, even if no SMILES found\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "standard_units\n",
       "mL.min-1.g-1              1102\n",
       "uL.min-1.(10^6cells)-1     408\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df['standard_units'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>assay_chembl_id</th>\n",
       "      <th>document_chembl_id</th>\n",
       "      <th>molecule_chembl_id</th>\n",
       "      <th>relation</th>\n",
       "      <th>standard_relation</th>\n",
       "      <th>standard_type</th>\n",
       "      <th>standard_units</th>\n",
       "      <th>standard_value</th>\n",
       "      <th>type</th>\n",
       "      <th>units</th>\n",
       "      <th>value</th>\n",
       "      <th>canonical_smiles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1407</th>\n",
       "      <td>CHEMBL3301372</td>\n",
       "      <td>CHEMBL3301361</td>\n",
       "      <td>CHEMBL945</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>CL</td>\n",
       "      <td>uL.min-1.(10^6cells)-1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>CLint</td>\n",
       "      <td>microL/min/1E6 cells</td>\n",
       "      <td>3.0</td>\n",
       "      <td>N=C(N)NC(=O)c1nc(Cl)c(N)nc1N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1485</th>\n",
       "      <td>CHEMBL3301370</td>\n",
       "      <td>CHEMBL3301361</td>\n",
       "      <td>CHEMBL945</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>CL</td>\n",
       "      <td>mL.min-1.g-1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>CLint</td>\n",
       "      <td>microL/min/mg</td>\n",
       "      <td>3.0</td>\n",
       "      <td>N=C(N)NC(=O)c1nc(Cl)c(N)nc1N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     assay_chembl_id document_chembl_id molecule_chembl_id relation  \\\n",
       "1407   CHEMBL3301372      CHEMBL3301361          CHEMBL945        <   \n",
       "1485   CHEMBL3301370      CHEMBL3301361          CHEMBL945        <   \n",
       "\n",
       "     standard_relation standard_type          standard_units  standard_value  \\\n",
       "1407                 <            CL  uL.min-1.(10^6cells)-1             3.0   \n",
       "1485                 <            CL            mL.min-1.g-1             3.0   \n",
       "\n",
       "       type                 units  value              canonical_smiles  \n",
       "1407  CLint  microL/min/1E6 cells    3.0  N=C(N)NC(=O)c1nc(Cl)c(N)nc1N  \n",
       "1485  CLint         microL/min/mg    3.0  N=C(N)NC(=O)c1nc(Cl)c(N)nc1N  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filt = merged_df['molecule_chembl_id'] == 'CHEMBL945'\n",
    "merged_df[filt]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Analysis + Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['assay_chembl_id', 'document_chembl_id', 'molecule_chembl_id',\n",
       "       'relation', 'standard_relation', 'standard_type', 'standard_units',\n",
       "       'standard_value', 'type', 'units', 'value'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activities_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities_df['standard_type'].value_counts().head(29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt = activities_df['standard_type'] == 'CL'\n",
    "activities_df[filt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp['document_chembl_id'].value_counts().head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "ax = sns.countplot(full_data, x='standard_type')\n",
    "plt.xticks(rotation=45, ha='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# 10k = 98s\n",
    "assays = assay.filter(\n",
    "    assay_type='A',\n",
    "    assay_organism__iexact='Homo sapiens'\n",
    ").only(['assay_type', 'description', 'assay_chembl_id', 'assay_organism'])[:10000]\n",
    "df = pd.DataFrame(assays)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Filter subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt = activities_df['standard_type'] == 'CL'\n",
    "tmp = activities_df[filt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt = activities_df['document_chembl_id'] == 'CHEMBL4342426'\n",
    "tmp = activities_df[filt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Look at molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data['mol_smi'] = full_data['molecule_structures'].apply(lambda x: x.get('canonical_smiles') if isinstance(x, dict) else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PandasTools.AddMoleculeColumnToFrame(\n",
    "    tmp, \n",
    "    smilesCol='mol_smi',  # Column containing SMILES strings\n",
    "    molCol='Molecule',             # Name of new column to create\n",
    "    includeFingerprints=False      # Set to True if you need fingerprints\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Extract hERG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chembl_webresource_client.new_client import new_client\n",
    "\n",
    "target = new_client.target\n",
    "activity = new_client.activity\n",
    "herg = target.filter(pref_name__iexact='hERG').only('target_chembl_id')[0]\n",
    "herg_activities = activity.filter(target_chembl_id=herg['target_chembl_id']).filter(standard_type=\"IC50\")\n",
    "\n",
    "herg_activities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Extract HLM data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_metabolic_assays(limit=1000):\n",
    "    url = f\"https://www.ebi.ac.uk/chembl/api/data/assay.json?assay_type=ADME&limit={limit}\"\n",
    "    assays = []\n",
    "    while url:\n",
    "        res = requests.get(url)\n",
    "        res.raise_for_status()\n",
    "        data = res.json()\n",
    "        for a in data[\"assays\"]:\n",
    "            if \"metabolic\" in (a.get(\"description\") or \"\").lower():\n",
    "                assays.append(a[\"assay_chembl_id\"])\n",
    "        url = data[\"page_meta\"][\"next\"]\n",
    "    return assays\n",
    "\n",
    "def fetch_activities_for_assays(assay_ids, limit=1000):\n",
    "    activities = []\n",
    "    for assay_id in assay_ids:\n",
    "        url = f\"https://www.ebi.ac.uk/chembl/api/data/activity.json?assay_chembl_id={assay_id}&limit={limit}\"\n",
    "        while url:\n",
    "            res = requests.get(url)\n",
    "            res.raise_for_status()\n",
    "            data = res.json()\n",
    "            activities.extend(data[\"activities\"])\n",
    "            url = data[\"page_meta\"][\"next\"]\n",
    "    return activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assay_ids = fetch_metabolic_assays()\n",
    "print(f\"Found {len(assay_ids)} assays likely related to metabolic stability.\")\n",
    "\n",
    "activities = fetch_activities_for_assays(assay_ids[:5])  # You can increase the slice\n",
    "print(f\"Retrieved {len(activities)} activity records.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_molecules_with_logp_and_docs(limit=100, max_pages=None, verbose=True):\n",
    "    url = f\"{base_url}/chembl/api/data/molecule.json?logp__isnull=false&molecule_documents__isnull=false&limit={limit}\"\n",
    "    molecules = []\n",
    "    page = 0\n",
    "    \n",
    "    while url and (max_pages is None or page < max_pages):\n",
    "        if verbose:\n",
    "            print(f\"Fetching page {page + 1}...\")\n",
    "        res = requests.get(url)\n",
    "        res.raise_for_status()\n",
    "        data = res.json()\n",
    "        molecules.extend(data['molecules'])\n",
    "\n",
    "        next_url = data['page_meta']['next']\n",
    "        url = f\"{base_url}{next_url}\" if next_url else None\n",
    "        page += 1\n",
    "\n",
    "    return molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "molecules = fetch_molecules_with_logp_and_docs(limit=50, max_pages=1)\n",
    "\n",
    "with open(\"../data/raw/chembl_logP_molecules.json\", \"w\") as f:\n",
    "    json.dump(molecules, f, indent=2)\n",
    "\n",
    "print(f\"Fetched {len(molecules)} molecules with logP.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(molecules)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['molecule_structures', 'molecule_chembl_id', 'molecule_properties']]\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test API with a known molecule Chembl ID\n",
    "chembl_id = \"CHEMBL6329\"\n",
    "url = f\"https://www.ebi.ac.uk/chembl/api/data/document.json?molecule_chembl_id={chembl_id}\"\n",
    "res = requests.get(url)\n",
    "res.raise_for_status()\n",
    "data = res.json()\n",
    "documents = data.get(\"documents\", [])\n",
    "df = pd.DataFrame(documents)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get all activities in CHemBL \n",
    "url = \"https://www.ebi.ac.uk/chembl/api/data/activity.json?limit=1000\"\n",
    "res = requests.get(url)\n",
    "res.raise_for_status()\n",
    "data = res.json()\n",
    "\n",
    "types = {a[\"standard_type\"] for a in data[\"activities\"] if a.get(\"standard_type\")}\n",
    "types = sorted(types)\n",
    "for t in types:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Get document_id for subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fetch documents associated with a molecule\n",
    "def get_documents_for_molecule(chembl_id):\n",
    "    url = f\"https://www.ebi.ac.uk/chembl/api/data/document.json?molecule_chembl_id={chembl_id}\"\n",
    "    res = requests.get(url)\n",
    "    res.raise_for_status()\n",
    "    return res.json().get(\"documents\", [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chembl_id = \"CHEMBL25\"\n",
    "documents = get_documents_for_molecule(chembl_id)\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add document IDs to each molecule\n",
    "def fetch_documents_for_molecules(molecules):\n",
    "    doc_map = {}\n",
    "    for mol in molecules:\n",
    "        chembl_id = mol.get(\"molecule_chembl_id\")\n",
    "        if chembl_id:\n",
    "            docs = get_documents_for_molecule(chembl_id)\n",
    "            doc_ids = [d[\"document_chembl_id\"] for d in docs]\n",
    "            doc_map[chembl_id] = doc_ids\n",
    "    return doc_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_map = fetch_documents_for_molecules(molecules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(molecules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"logP\"] = df[\"molecule_properties\"].apply(\n",
    "    lambda x: x.get(\"alogp\") if isinstance(x, dict) else None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"document_ids\"] = df[\"molecule_chembl_id\"].map(doc_map)\n",
    "\n",
    "# Show merged DataFrame\n",
    "df_merged = df[[\"molecule_chembl_id\", \"logP\", \"document_ids\"]]\n",
    "print(df_merged.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Get molecules from document_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_molecules_for_document(document_id):\n",
    "    url = f\"https://www.ebi.ac.uk/chembl/api/data/molecule_document.json?document_chembl_id={document_id}\"\n",
    "    res = requests.get(url)\n",
    "    res.raise_for_status()\n",
    "    return res.json().get(\"molecule_documents\", [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Get molecules associated with a document\n",
    "document_id = \"CHEMBL1158643\"\n",
    "molecule_docs = get_molecules_for_document(document_id)\n",
    "\n",
    "# Print out the molecule ChEMBL IDs\n",
    "molecule_ids = [doc[\"molecule_chembl_id\"] for doc in molecule_docs]\n",
    "print(f\"Molecule ChEMBL IDs for document {document_id}: {molecule_ids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_molecules_with_logp_and_patents(limit=100, max_pages=None, verbose=True):\n",
    "    base_url = \"https://www.ebi.ac.uk\"\n",
    "    url = f\"{base_url}/chembl/api/data/molecule.json?logp__isnull=false&molecule_patents__isnull=false&limit={limit}\"\n",
    "    molecules = []\n",
    "    page = 0\n",
    "\n",
    "    while url and (max_pages is None or page < max_pages):\n",
    "        if verbose:\n",
    "            print(f\"Fetching page {page + 1}...\")\n",
    "        res = requests.get(url)\n",
    "        res.raise_for_status()\n",
    "        data = res.json()\n",
    "        molecules.extend(data['molecules'])\n",
    "\n",
    "        next_url = data['page_meta'].get('next')\n",
    "        url = f\"{base_url}{next_url}\" if next_url else None\n",
    "        page += 1\n",
    "\n",
    "    return molecules\n",
    "\n",
    "def fetch_molecules_with_logp_smiles_and_patents(limit=100, max_pages=None, verbose=True):\n",
    "    base_url = \"https://www.ebi.ac.uk\"\n",
    "    url = f\"{base_url}/chembl/api/data/molecule.json?logp__isnull=false&molecule_patents__isnull=false&limit={limit}\"\n",
    "    molecules = []\n",
    "    page = 0\n",
    "\n",
    "    while url and (max_pages is None or page < max_pages):\n",
    "        if verbose:\n",
    "            print(f\"Fetching page {page + 1}...\")\n",
    "        res = requests.get(url)\n",
    "        res.raise_for_status()\n",
    "        data = res.json()\n",
    "        molecules.extend(data['molecules'])\n",
    "\n",
    "        next_url = data['page_meta'].get('next')\n",
    "        url = f\"{base_url}{next_url}\" if next_url else None\n",
    "        page += 1\n",
    "\n",
    "    # Fetch SMILES and Patent IDs for each molecule\n",
    "    molecules_with_smiles_and_patents = []\n",
    "    for molecule in molecules:\n",
    "        patent_ids = []\n",
    "        smiles = None\n",
    "        \n",
    "        # Get SMILES from molecule_structures\n",
    "        if 'molecule_structures' in molecule:\n",
    "            smiles = molecule['molecule_structures'].get('canonical_smiles', None)\n",
    "        \n",
    "        # Get patent IDs from molecule_patents\n",
    "        if 'molecule_patents' in molecule:\n",
    "            patent_ids = [patent['patent_chembl_id'] for patent in molecule['molecule_patents']]\n",
    "        \n",
    "        # Add SMILES and patent IDs to molecule data\n",
    "        molecule['smiles'] = smiles\n",
    "        molecule['patent_ids'] = patent_ids\n",
    "        molecules_with_smiles_and_patents.append(molecule)\n",
    "\n",
    "    return molecules_with_smiles_and_patents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
